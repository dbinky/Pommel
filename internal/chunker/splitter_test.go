package chunker

import (
	"fmt"
	"strings"
	"testing"

	"github.com/pommel-dev/pommel/internal/embedder"
	"github.com/pommel-dev/pommel/internal/models"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
)

// =============================================================================
// Splitter Construction Tests
// =============================================================================

// --- Happy Path Tests ---

func TestNewSplitter_DefaultValues(t *testing.T) {
	s := NewSplitter(8000)

	assert.Equal(t, 8000, s.maxTokens)
	assert.Equal(t, 256, s.overlapTokens)
}

func TestNewSplitter_DifferentProviderLimits(t *testing.T) {
	tests := []struct {
		name      string
		maxTokens int
	}{
		{"Ollama", 8000},
		{"OpenAI", 8000},
		{"Voyage", 15000},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			s := NewSplitter(tt.maxTokens)
			assert.Equal(t, tt.maxTokens, s.maxTokens)
		})
	}
}

// --- Edge Case Tests ---

func TestNewSplitter_ZeroMaxTokens(t *testing.T) {
	s := NewSplitter(0)
	// Should handle gracefully - use minimum
	assert.True(t, s.maxTokens >= 100)
}

func TestNewSplitter_NegativeMaxTokens(t *testing.T) {
	s := NewSplitter(-100)
	// Should handle gracefully
	assert.True(t, s.maxTokens >= 100)
}

// =============================================================================
// SplitChunk Type Tests
// =============================================================================

func TestSplitChunk_ToChunk_NonSplit(t *testing.T) {
	original := &models.Chunk{
		ID:       "original-1",
		FilePath: "src/main.go",
		Name:     "main",
		Level:    models.ChunkLevelMethod,
	}

	split := SplitChunk{
		Content:   "func main() {}",
		StartLine: 10,
		EndLine:   20,
		Index:     0,
		IsPartial: false,
		ParentID:  "",
	}

	chunk := split.ToChunk(original)
	chunk.SetHashes() // Caller is responsible for setting hashes

	assert.NotEmpty(t, chunk.ID) // ID generated by SetHashes
	assert.Equal(t, "src/main.go", chunk.FilePath)
	assert.Equal(t, "main", chunk.Name)
	assert.Equal(t, 10, chunk.StartLine)
	assert.Equal(t, 20, chunk.EndLine)
	assert.Equal(t, "func main() {}", chunk.Content)
	assert.False(t, chunk.IsPartial)
	assert.Equal(t, "", chunk.ParentChunkID)
}

func TestSplitChunk_ToChunk_Split(t *testing.T) {
	original := &models.Chunk{
		ID:       "original-1",
		FilePath: "src/main.go",
		Name:     "bigMethod",
		Level:    models.ChunkLevelMethod,
	}

	split := SplitChunk{
		Content:   "first part of method",
		StartLine: 10,
		EndLine:   50,
		Index:     0,
		IsPartial: true,
		ParentID:  "original-1",
	}

	chunk := split.ToChunk(original)

	assert.True(t, chunk.IsPartial)
	assert.Equal(t, "original-1", chunk.ParentChunkID)
	assert.Equal(t, 0, chunk.ChunkIndex)
	assert.Equal(t, 10, chunk.StartLine)
	assert.Equal(t, 50, chunk.EndLine)
}

func TestSplitChunk_ToChunk_PreservesLevel(t *testing.T) {
	levels := []models.ChunkLevel{
		models.ChunkLevelFile,
		models.ChunkLevelClass,
		models.ChunkLevelMethod,
	}

	for _, level := range levels {
		t.Run(string(level), func(t *testing.T) {
			original := &models.Chunk{Level: level}
			split := SplitChunk{Content: "test"}
			chunk := split.ToChunk(original)
			assert.Equal(t, level, chunk.Level)
		})
	}
}

// =============================================================================
// HandleFileChunk Tests
// =============================================================================

// --- Happy Path Tests ---

func TestHandleFileChunk_SmallFile_PassThrough(t *testing.T) {
	s := NewSplitter(8000)
	chunk := &models.Chunk{
		Content:   "package main\n\nfunc main() {}\n",
		Level:     models.ChunkLevelFile,
		StartLine: 1,
		EndLine:   3,
	}

	result := s.HandleFileChunk(chunk, len(chunk.Content))

	require.NotNil(t, result)
	assert.Equal(t, chunk.Content, result.Content)
	assert.False(t, result.IsPartial)
}

func TestHandleFileChunk_MediumFile_WithinTokenLimit(t *testing.T) {
	s := NewSplitter(8000)
	// Create content that's under token limit but decent size
	content := strings.Repeat("func foo() { return 1 }\n", 500) // ~12KB
	chunk := &models.Chunk{
		Content:   content,
		Level:     models.ChunkLevelFile,
		StartLine: 1,
		EndLine:   500,
	}

	result := s.HandleFileChunk(chunk, len(content))

	require.NotNil(t, result)
	assert.Equal(t, content, result.Content)
	assert.False(t, result.IsPartial)
}

// --- Success Tests: Truncation ---

func TestHandleFileChunk_OversizedContent_Truncates(t *testing.T) {
	s := NewSplitter(1000) // Low limit for testing
	// Create content that exceeds token limit
	content := strings.Repeat("x", 5000) // ~1428 tokens, over 1000 limit
	chunk := &models.Chunk{
		Content:   content,
		Level:     models.ChunkLevelFile,
		StartLine: 1,
		EndLine:   1,
	}

	result := s.HandleFileChunk(chunk, len(content))

	require.NotNil(t, result)
	assert.True(t, result.IsPartial)
	assert.Less(t, len(result.Content), len(content))
	assert.Contains(t, result.Content, "[truncated]")
}

func TestHandleFileChunk_TruncatesAtLineBreak(t *testing.T) {
	s := NewSplitter(100) // Very low limit
	content := "line1\nline2\nline3\nline4\nline5\n" + strings.Repeat("x", 500)
	chunk := &models.Chunk{
		Content:   content,
		Level:     models.ChunkLevelFile,
		StartLine: 1,
		EndLine:   10,
	}

	result := s.HandleFileChunk(chunk, len(content))

	require.NotNil(t, result)
	assert.True(t, result.IsPartial)
	// Should contain truncation marker
	assert.Contains(t, result.Content, "[truncated]")
}

// --- Success Tests: Skip Very Large Files ---

func TestHandleFileChunk_VeryLargeFile_ReturnsNil(t *testing.T) {
	s := NewSplitter(8000)
	content := strings.Repeat("x", 50*1024) // 50KB content
	chunk := &models.Chunk{
		Content: content,
		Level:   models.ChunkLevelFile,
	}

	// File size is 150KB, over 100KB limit
	result := s.HandleFileChunk(chunk, 150*1024)

	assert.Nil(t, result, "Should skip file-level chunk for files > 100KB")
}

func TestHandleFileChunk_ExactlyAtSizeLimit_NotSkipped(t *testing.T) {
	s := NewSplitter(8000)
	content := "small content"
	chunk := &models.Chunk{
		Content: content,
		Level:   models.ChunkLevelFile,
	}

	// Exactly at 100KB limit
	result := s.HandleFileChunk(chunk, 100*1024)

	require.NotNil(t, result, "Should not skip file at exactly 100KB")
}

func TestHandleFileChunk_JustOverSizeLimit_Skipped(t *testing.T) {
	s := NewSplitter(8000)
	content := "small content"
	chunk := &models.Chunk{
		Content: content,
		Level:   models.ChunkLevelFile,
	}

	// 1 byte over 100KB limit
	result := s.HandleFileChunk(chunk, 100*1024+1)

	assert.Nil(t, result, "Should skip file just over 100KB")
}

// --- Edge Case Tests ---

func TestHandleFileChunk_EmptyContent(t *testing.T) {
	s := NewSplitter(8000)
	chunk := &models.Chunk{
		Content: "",
		Level:   models.ChunkLevelFile,
	}

	result := s.HandleFileChunk(chunk, 0)

	require.NotNil(t, result)
	assert.Equal(t, "", result.Content)
	assert.False(t, result.IsPartial)
}

func TestHandleFileChunk_NilChunk(t *testing.T) {
	s := NewSplitter(8000)
	result := s.HandleFileChunk(nil, 1000)
	assert.Nil(t, result)
}

func TestHandleFileChunk_ZeroFileSize(t *testing.T) {
	s := NewSplitter(8000)
	chunk := &models.Chunk{
		Content: "some content",
		Level:   models.ChunkLevelFile,
	}

	result := s.HandleFileChunk(chunk, 0)
	require.NotNil(t, result)
}

func TestHandleFileChunk_SingleLineContent(t *testing.T) {
	s := NewSplitter(100) // Low limit
	content := strings.Repeat("x", 500) // Single line, will be truncated
	chunk := &models.Chunk{
		Content:   content,
		Level:     models.ChunkLevelFile,
		StartLine: 1,
		EndLine:   1,
	}

	result := s.HandleFileChunk(chunk, len(content))

	require.NotNil(t, result)
	assert.True(t, result.IsPartial)
}

func TestHandleFileChunk_PreservesLineNumbers(t *testing.T) {
	s := NewSplitter(8000)
	chunk := &models.Chunk{
		Content:   "content",
		Level:     models.ChunkLevelFile,
		StartLine: 5,
		EndLine:   10,
	}

	result := s.HandleFileChunk(chunk, len(chunk.Content))

	assert.Equal(t, 5, result.StartLine)
	assert.Equal(t, 10, result.EndLine)
}

// =============================================================================
// HandleClassChunk Tests
// =============================================================================

// --- Happy Path Tests ---

func TestHandleClassChunk_SmallClass_PassThrough(t *testing.T) {
	s := NewSplitter(8000)
	content := `class Calculator:
    def __init__(self):
        self.value = 0

    def add(self, x):
        self.value += x
`
	chunk := &models.Chunk{
		Content:   content,
		Level:     models.ChunkLevelClass,
		StartLine: 1,
		EndLine:   7,
	}

	result := s.HandleClassChunk(chunk)

	require.NotNil(t, result)
	assert.Equal(t, content, result.Content)
	assert.False(t, result.IsPartial)
}

// --- Success Tests: Truncation ---

func TestHandleClassChunk_LargeClass_Truncates(t *testing.T) {
	s := NewSplitter(500) // Low limit for testing
	// Create large class content
	methods := strings.Repeat("    def method(self):\n        pass\n\n", 100)
	content := "class BigClass:\n" + methods
	chunk := &models.Chunk{
		Content:   content,
		Level:     models.ChunkLevelClass,
		StartLine: 1,
		EndLine:   300,
	}

	result := s.HandleClassChunk(chunk)

	require.NotNil(t, result)
	assert.True(t, result.IsPartial)
	assert.Less(t, len(result.Content), len(content))
	assert.Contains(t, result.Content, "[truncated]")
}

func TestHandleClassChunk_PreservesClassSignature(t *testing.T) {
	s := NewSplitter(200) // Very low limit
	content := `type DatabaseConnection struct {
	host     string
	port     int
	username string
	password string
}

func (db *DatabaseConnection) Connect() error {
	// lots of code here
` + strings.Repeat("    // more code\n", 50) + "}"

	chunk := &models.Chunk{
		Content:   content,
		Level:     models.ChunkLevelClass,
		StartLine: 1,
		EndLine:   60,
	}

	result := s.HandleClassChunk(chunk)

	require.NotNil(t, result)
	// Should preserve the struct definition at minimum
	assert.Contains(t, result.Content, "type DatabaseConnection struct")
}

// --- Edge Case Tests ---

func TestHandleClassChunk_EmptyClass(t *testing.T) {
	s := NewSplitter(8000)
	chunk := &models.Chunk{
		Content:   "class Empty:\n    pass\n",
		Level:     models.ChunkLevelClass,
		StartLine: 1,
		EndLine:   2,
	}

	result := s.HandleClassChunk(chunk)

	require.NotNil(t, result)
	assert.False(t, result.IsPartial)
}

func TestHandleClassChunk_NilChunk(t *testing.T) {
	s := NewSplitter(8000)
	result := s.HandleClassChunk(nil)
	assert.Nil(t, result)
}

func TestHandleClassChunk_EmptyContent(t *testing.T) {
	s := NewSplitter(8000)
	chunk := &models.Chunk{
		Content: "",
		Level:   models.ChunkLevelClass,
	}

	result := s.HandleClassChunk(chunk)

	require.NotNil(t, result)
	assert.Equal(t, "", result.Content)
}

func TestHandleClassChunk_SingleLineClass(t *testing.T) {
	s := NewSplitter(100) // Low limit
	content := "class Foo { " + strings.Repeat("x", 500) + " }"
	chunk := &models.Chunk{
		Content:   content,
		Level:     models.ChunkLevelClass,
		StartLine: 1,
		EndLine:   1,
	}

	result := s.HandleClassChunk(chunk)

	require.NotNil(t, result)
	assert.True(t, result.IsPartial)
}

func TestHandleClassChunk_PreservesLineNumbers(t *testing.T) {
	s := NewSplitter(8000)
	chunk := &models.Chunk{
		Content:   "class Foo {}",
		Level:     models.ChunkLevelClass,
		StartLine: 15,
		EndLine:   25,
	}

	result := s.HandleClassChunk(chunk)

	assert.Equal(t, 15, result.StartLine)
	assert.Equal(t, 25, result.EndLine)
}

// =============================================================================
// SplitMethod Tests
// =============================================================================

// --- Happy Path Tests ---

func TestSplitMethod_SmallMethod_NoSplit(t *testing.T) {
	s := NewSplitter(8000)
	content := `func add(a, b int) int {
	return a + b
}`
	chunk := &models.Chunk{
		ID:        "chunk-1",
		Content:   content,
		Level:     models.ChunkLevelMethod,
		StartLine: 1,
		EndLine:   3,
	}

	splits := s.SplitMethod(chunk)

	require.Len(t, splits, 1)
	assert.Equal(t, content, splits[0].Content)
	assert.False(t, splits[0].IsPartial)
	assert.Equal(t, "", splits[0].ParentID)
	assert.Equal(t, 0, splits[0].Index)
}

func TestSplitMethod_LargeMethod_CreatesSplits(t *testing.T) {
	s := NewSplitter(500) // Low limit to force splitting
	// Create large method content
	lines := make([]string, 100)
	for i := range lines {
		lines[i] = "    x := doSomething()\n"
	}
	content := "func bigMethod() {\n" + strings.Join(lines, "") + "}\n"

	chunk := &models.Chunk{
		ID:        "chunk-1",
		Content:   content,
		Level:     models.ChunkLevelMethod,
		StartLine: 1,
		EndLine:   102,
	}

	splits := s.SplitMethod(chunk)

	assert.Greater(t, len(splits), 1, "Should create multiple splits")
	for i, split := range splits {
		assert.True(t, split.IsPartial)
		assert.Equal(t, "chunk-1", split.ParentID)
		assert.Equal(t, i, split.Index)
	}
}

func TestSplitMethod_SplitsHaveOverlap(t *testing.T) {
	s := NewSplitter(300) // Low limit
	// Create content that will be split
	var lines []string
	for i := 0; i < 50; i++ {
		lines = append(lines, fmt.Sprintf("line %d: some code here\n", i))
	}
	content := strings.Join(lines, "")

	chunk := &models.Chunk{
		ID:        "chunk-1",
		Content:   content,
		Level:     models.ChunkLevelMethod,
		StartLine: 1,
		EndLine:   50,
	}

	splits := s.SplitMethod(chunk)

	require.Greater(t, len(splits), 1)

	// Check that consecutive splits have reasonable continuity
	// (may have small gaps due to line-based splitting, but should be close)
	for i := 0; i < len(splits)-1; i++ {
		current := splits[i]
		next := splits[i+1]

		// Next split should start within a few lines of current end
		gap := next.StartLine - current.EndLine
		assert.LessOrEqual(t, gap, 5,
			"Split %d and %d should have minimal gap (got %d)", i, i+1, gap)
	}
}

func TestSplitMethod_CoverageComplete(t *testing.T) {
	s := NewSplitter(400) // Force splitting
	var lines []string
	for i := 0; i < 60; i++ {
		lines = append(lines, fmt.Sprintf("line%d\n", i))
	}
	content := strings.Join(lines, "")

	chunk := &models.Chunk{
		ID:        "chunk-1",
		Content:   content,
		Level:     models.ChunkLevelMethod,
		StartLine: 1,
		EndLine:   60,
	}

	splits := s.SplitMethod(chunk)

	// Verify all content is covered
	allContent := ""
	for _, split := range splits {
		allContent += split.Content
	}

	// Original content should be fully represented (with possible overlap duplicates)
	for _, line := range lines {
		assert.Contains(t, allContent, strings.TrimSpace(line),
			"All original lines should be in splits")
	}
}

// --- Success Tests ---

func TestSplitMethod_ExactlyAtLimit_NoSplit(t *testing.T) {
	s := NewSplitter(100)
	// Create content exactly at 100 tokens (~350 chars)
	content := strings.Repeat("x", 350)
	chunk := &models.Chunk{
		Content:   content,
		Level:     models.ChunkLevelMethod,
		StartLine: 1,
		EndLine:   1,
	}

	splits := s.SplitMethod(chunk)

	assert.Len(t, splits, 1)
	assert.False(t, splits[0].IsPartial)
}

func TestSplitMethod_JustOverLimit_CreatesSplits(t *testing.T) {
	s := NewSplitter(100)
	// Create content well over 100 tokens to ensure splitting
	content := strings.Repeat("some code here with enough text\n", 50) // ~1550 chars, ~443 tokens
	chunk := &models.Chunk{
		Content:   content,
		Level:     models.ChunkLevelMethod,
		StartLine: 1,
		EndLine:   50,
	}

	splits := s.SplitMethod(chunk)

	assert.Greater(t, len(splits), 1)
}

// --- Edge Case Tests ---

func TestSplitMethod_NilChunk(t *testing.T) {
	s := NewSplitter(8000)
	splits := s.SplitMethod(nil)
	assert.Empty(t, splits)
}

func TestSplitMethod_EmptyContent(t *testing.T) {
	s := NewSplitter(8000)
	chunk := &models.Chunk{
		Content: "",
		Level:   models.ChunkLevelMethod,
	}

	splits := s.SplitMethod(chunk)

	assert.Len(t, splits, 1)
	assert.Equal(t, "", splits[0].Content)
}

func TestSplitMethod_SingleCharacter(t *testing.T) {
	s := NewSplitter(8000)
	chunk := &models.Chunk{
		Content:   "x",
		Level:     models.ChunkLevelMethod,
		StartLine: 1,
		EndLine:   1,
	}

	splits := s.SplitMethod(chunk)

	assert.Len(t, splits, 1)
	assert.Equal(t, "x", splits[0].Content)
}

func TestSplitMethod_VeryLongSingleLine(t *testing.T) {
	s := NewSplitter(500)
	// Single line that exceeds token limit
	// Note: Line-based splitting can't split a single line, so it will
	// return just one split containing the full line (marked as partial)
	content := strings.Repeat("x", 5000)
	chunk := &models.Chunk{
		Content:   content,
		Level:     models.ChunkLevelMethod,
		StartLine: 1,
		EndLine:   1,
	}

	splits := s.SplitMethod(chunk)

	// With no line breaks, we can only have one split per line
	require.Len(t, splits, 1)
	// It should be marked as partial since it exceeds the limit
	assert.True(t, splits[0].IsPartial || embedder.EstimateTokens(content) <= s.maxTokens)
}

func TestSplitMethod_LineNumbersCorrect(t *testing.T) {
	s := NewSplitter(200) // Force splitting
	var lines []string
	for i := 0; i < 30; i++ {
		lines = append(lines, fmt.Sprintf("line %d\n", i))
	}
	content := strings.Join(lines, "")

	chunk := &models.Chunk{
		Content:   content,
		Level:     models.ChunkLevelMethod,
		StartLine: 100, // Starting at line 100
		EndLine:   129,
	}

	splits := s.SplitMethod(chunk)

	// First split should start at original start line
	assert.Equal(t, 100, splits[0].StartLine)

	// Last split should end at or before original end line
	lastSplit := splits[len(splits)-1]
	assert.LessOrEqual(t, lastSplit.EndLine, 129)

	// Line numbers should be sequential
	for i := 0; i < len(splits)-1; i++ {
		current := splits[i]
		next := splits[i+1]
		assert.LessOrEqual(t, next.StartLine, current.EndLine+1)
	}
}

func TestSplitMethod_PreservesOriginalID(t *testing.T) {
	s := NewSplitter(200)
	content := strings.Repeat("line\n", 50)
	chunk := &models.Chunk{
		ID:        "original-method-123",
		Content:   content,
		Level:     models.ChunkLevelMethod,
		StartLine: 1,
		EndLine:   50,
	}

	splits := s.SplitMethod(chunk)

	for _, split := range splits {
		if split.IsPartial {
			assert.Equal(t, "original-method-123", split.ParentID)
		}
	}
}

func TestSplitMethod_IndexesSequential(t *testing.T) {
	s := NewSplitter(200)
	content := strings.Repeat("line of code here\n", 40)
	chunk := &models.Chunk{
		ID:        "chunk-1",
		Content:   content,
		Level:     models.ChunkLevelMethod,
		StartLine: 1,
		EndLine:   40,
	}

	splits := s.SplitMethod(chunk)

	for i, split := range splits {
		assert.Equal(t, i, split.Index, "Index should be sequential")
	}
}

// --- Failure Scenario Tests ---

func TestSplitMethod_ContentExceedsSafeLimit(t *testing.T) {
	s := NewSplitter(200) // Reasonable limit
	// Content much larger than limit with multiple lines
	var lines []string
	for i := 0; i < 100; i++ {
		lines = append(lines, fmt.Sprintf("line %d with some code\n", i))
	}
	content := strings.Join(lines, "")
	chunk := &models.Chunk{
		Content:   content,
		Level:     models.ChunkLevelMethod,
		StartLine: 1,
		EndLine:   100,
	}

	// Should not panic, should handle gracefully
	splits := s.SplitMethod(chunk)

	assert.NotEmpty(t, splits)
	assert.Greater(t, len(splits), 1)
	// All splits should be within a reasonable range
	for _, split := range splits {
		tokens := embedder.EstimateTokens(split.Content)
		// Allow tolerance for overlap
		assert.LessOrEqual(t, tokens, s.maxTokens+s.overlapTokens+50,
			"Split content should be approximately within limit")
	}
}
